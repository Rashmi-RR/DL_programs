{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "# from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing and loading\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,download=False, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,download=False, transform=transform)\n",
    "train_subset = Subset(train_dataset, range(200))\n",
    "test_subset = Subset(test_dataset, range(50))\n",
    "train_loader = DataLoader(train_subset, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(test_subset, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv_block1 = nn.Sequential(nn.Conv2d(3, 32, kernel_size=3, padding=1),nn.ReLU(),nn.MaxPool2d(2))\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "        nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.ReLU(),nn.MaxPool2d(2))\n",
    "        self.dense1 = nn.Linear(64 * 8 * 8, 512)\n",
    "        self.dense2 = nn.Linear(512, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNWithBNDropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNWithBNDropout, self).__init__()\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "        nn.Conv2d(3, 32, kernel_size=3, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "        nn.Conv2d(32, 64, kernel_size=3, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.dense1 = nn.Linear(64 * 8 * 8, 512)\n",
    "        self.dense2 = nn.Linear(512, 10)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = SimpleCNN()\n",
    "model2 = CNNWithBNDropout()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer1 = optim.Adam(model1.parameters(), lr=0.001)\n",
    "optimizer2 = optim.Adam(model2.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20], Train Loss: 2.2554,rain Accuracy: 13.5000%, Test Loss: 0.4482, TestAccuracy: 10.0000%\n",
      "Epoch: [20/20], Train Loss: 2.2554,rain Accuracy: 13.5000%, Test Loss: 0.8963, TestAccuracy: 15.0000%\n",
      "Epoch: [20/20], Train Loss: 2.2554,rain Accuracy: 13.5000%, Test Loss: 1.3558, TestAccuracy: 13.3333%\n",
      "Epoch: [20/20], Train Loss: 2.2554,rain Accuracy: 13.5000%, Test Loss: 1.7967, TestAccuracy: 15.0000%\n",
      "Epoch: [20/20], Train Loss: 2.2554,rain Accuracy: 13.5000%, Test Loss: 2.2533, TestAccuracy: 16.0000%\n",
      "Epoch: [30/30], Train Loss: 2.5176,rain Accuracy: 18.0000%, Test Loss: 0.3964, TestAccuracy: 20.0000%\n",
      "Epoch: [30/30], Train Loss: 2.5176,rain Accuracy: 18.0000%, Test Loss: 0.8742, TestAccuracy: 15.0000%\n",
      "Epoch: [30/30], Train Loss: 2.5176,rain Accuracy: 18.0000%, Test Loss: 1.3474, TestAccuracy: 13.3333%\n",
      "Epoch: [30/30], Train Loss: 2.5176,rain Accuracy: 18.0000%, Test Loss: 1.8105, TestAccuracy: 12.5000%\n",
      "Epoch: [30/30], Train Loss: 2.5176,rain Accuracy: 18.0000%, Test Loss: 2.2876, TestAccuracy: 10.0000%\n"
     ]
    }
   ],
   "source": [
    "def train(model, optimizer, criterion, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "    for data, target in train_loader:\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        predicted = torch.argmax(output.data, dim=1)\n",
    "        total_train += target.size(0)\n",
    "        correct_train += (predicted == target).sum().item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    train_acc = 100 * correct_train / total_train\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            test_loss += loss.item()\n",
    "            predicted = torch.argmax(output.data, dim=1)\n",
    "            total_test += target.size(0)\n",
    "            correct_test += (predicted==target).sum().item()\n",
    "            avg_test_loss = test_loss/len(test_loader)\n",
    "            test_acc = 100 * correct_test/total_test\n",
    "            print(f'Epoch: [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f},rain Accuracy: {train_acc:.4f}%, Test Loss: {avg_test_loss:.4f}, TestAccuracy: {test_acc:.4f}%')\n",
    "\n",
    "\n",
    "train(model1, optimizer1, criterion, 20)\n",
    "train(model2, optimizer2, criterion, 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
